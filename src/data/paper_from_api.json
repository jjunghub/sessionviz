{
  "famous": [
    {
      "title": "Natural Language Processing (almost) from Scratch",
      "authors": "['cereb_116781', 'cereb_116782', 'cereb_116783', 'cereb_116784', 'cereb_116785', 'cereb_79648']",
      "abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements. \u00a9 2011 Ronan Collobert, Jason Weston, L\u00e9on Bottou, Michael Karlen, Koray Kavukcuoglu and Pavel Kuksa.",
      "publication": "Journal of Machine Learning Research",
      "pub_year": 2011,
      "cereb_cite": 268,
      "max_cite": 1744,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 4 },
        { "year": 2014, "cite": 16 },
        { "year": 2015, "cite": 45 },
        { "year": 2016, "cite": 66 },
        { "year": 2017, "cite": 85 },
        { "year": 2018, "cite": 52 }
      ]
    },
    {
      "title": "Annotating expressions of opinions and emotions in language",
      "authors": "['cereb_117872', 'cereb_117871', 'cereb_126709']",
      "abstract": "This paper describes a corpus annotation project to study issues in the manual annotation of opinions, emotions, sentiments, speculations, evaluations and other private states in language. The resulting corpus annotation scheme is described, as well as examples of its use. In addition, the manual annotation process and the results of an inter-annotator agreement study on a 10,000-sentence corpus of articles drawn from the world press are presented. \u00a9 Springer 2006.",
      "publication": "Language Resources and Evaluation",
      "pub_year": 2005,
      "cereb_cite": 56,
      "max_cite": 651,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 2 },
        { "year": 2007, "cite": 4 },
        { "year": 2008, "cite": 5 },
        { "year": 2009, "cite": 2 },
        { "year": 2010, "cite": 6 },
        { "year": 2011, "cite": 3 },
        { "year": 2012, "cite": 3 },
        { "year": 2013, "cite": 6 },
        { "year": 2014, "cite": 2 },
        { "year": 2015, "cite": 7 },
        { "year": 2016, "cite": 8 },
        { "year": 2017, "cite": 5 },
        { "year": 2018, "cite": 3 }
      ]
    },
    {
      "title": "Deep Learning-Based Document Modeling for Personality Detection from Text",
      "authors": "['cereb_215378', 'cereb_165089', 'cereb_2905', 'cereb_134926']",
      "abstract": "This article presents a deep learning based method for determining the author's personality type from text: given a text, the presence or absence of the Big Five traits is detected in the author's psychological profile. For each of the five traits, the authors train a separate binary classifier, with identical architecture, based on a novel document modeling technique. Namely, the classifier is implemented as a specially designed deep convolutional neural network, with injection of the document-level Mairesse features, extracted directly from the text, into an inner layer. The first layers of the network treat each sentence of the text separately; then the sentences are aggregated into the document vector. Filtering out emotionally neutral input sentences improved the performance. This method outperformed the state of the art for all five traits, and the implementation is freely available for research purposes.",
      "publication": "IEEE Intelligent Systems",
      "pub_year": 2017,
      "cereb_cite": 35,
      "max_cite": 39,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 20 },
        { "year": 2018, "cite": 15 }
      ]
    },
    {
      "title": "Deep learning: yesterday, today, and tomorrow",
      "authors": "['cereb_115723', 'cereb_159706', 'cereb_155351', 'cereb_122149']",
      "abstract": "Machine learning is an important area of artificial intelligence. Since 1980s, huge success has been achieved in terms of algorithms, theory, and applications. From 2006, a new machine learning paradigm, named deep learning, has been popular in the research community, and has become a huge wave of technology trend for big data and artificial intelligence. Deep learning simulates the hierarchical structure of human brain, processing data from lower level to higher level, and gradually composing more and more semantic concepts. In recent years, Google, Microsoft, IBM, and Baidu have invested a lot of resources into the R&D of deep learning, making significant progresses on speech recognition, image understanding, natural language processing, and online advertising. In terms of the contribution to real-world applications, deep learning is perhaps the most successful progress made by the machine learning community in the last 10 years. In this article, we will give a high-level overview about the past and current stage of deep learning, discuss the main challenges, and share our views on the future development of deep learning.",
      "publication": "Jisuanji Yanjiu yu FazhanComputer Research and Development",
      "pub_year": 2013,
      "cereb_cite": 34,
      "max_cite": 73,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 2 },
        { "year": 2015, "cite": 6 },
        { "year": 2016, "cite": 9 },
        { "year": 2017, "cite": 13 },
        { "year": 2018, "cite": 4 }
      ]
    },
    {
      "title": "GENIA corpus - A semantically annotated corpus for bio-textmining",
      "authors": "['cereb_56283', 'cereb_131765', 'cereb_131766', 'cereb_131767']",
      "abstract": "Motivation: Natural language processing (NLP) methods are regarded as being useful to raise the potential of text mining from biological literature. The lack of an extensively annotated corpus of this literature, however, causes a major bottleneck for applying NLP techniques. GENIA corpus is being developed to provide reference materials to let NLP techniques work for bio-textmining. Results: GENIA corpus version 3.0 consisting of 2000 MEDLINE abstracts has been released with more than 400000 words and almost 100000 annotations for biological terms. Availability: GENIA corpus is freely available at http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA. \u00a9 Oxford University Press 2003; all rights reserved.",
      "publication": "Bioinformatics",
      "pub_year": 2003,
      "cereb_cite": 32,
      "max_cite": 479,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 2 },
        { "year": 2006, "cite": 3 },
        { "year": 2007, "cite": 1 },
        { "year": 2008, "cite": 3 },
        { "year": 2009, "cite": 1 },
        { "year": 2010, "cite": 2 },
        { "year": 2011, "cite": 2 },
        { "year": 2012, "cite": 4 },
        { "year": 2013, "cite": 1 },
        { "year": 2014, "cite": 2 },
        { "year": 2015, "cite": 3 },
        { "year": 2016, "cite": 3 },
        { "year": 2017, "cite": 3 },
        { "year": 2018, "cite": 2 }
      ]
    },
    {
      "title": "A review of natural language processing techniques for opinion mining systems",
      "authors": "['cereb_142823', 'cereb_230949', 'cereb_230950']",
      "abstract": "\u00a9 2016 Elsevier B.V. As the prevalence of social media on the Internet, opinion mining has become an essential approach to analyzing so many data. Various applications appear in a wide range of industrial domains. Meanwhile, opinions have diverse expressions which bring along research challenges. Both of the practical demands and research challenges make opinion mining an active research area in recent years. In this paper, we present a review of Natural Language Processing (NLP) techniques for opinion mining. First, we introduce general NLP techniques which are required for text preprocessing. Second, we investigate the approaches of opinion mining for different levels and situations. Then we introduce comparative opinion mining and deep learning approaches for opinion mining. Opinion summarization and advanced topics are introduced later. Finally, we discuss some challenges and open problems related to opinion mining.",
      "publication": "Information Fusion",
      "pub_year": 2017,
      "cereb_cite": 18,
      "max_cite": 29,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 7 },
        { "year": 2018, "cite": 11 }
      ]
    },
    {
      "title": "Using lexical chains for keyword extraction",
      "authors": "['cereb_168177', 'cereb_168178']",
      "abstract": "Keywords can be considered as condensed versions of documents and short forms of their summaries. In this paper, the problem of automatic extraction of keywords from documents is treated as a supervised learning task. A lexical chain holds a set of semantically related words of a text and it can be said that a lexical chain represents the semantic content of a portion of the text. Although lexical chains have been extensively used in text summarization, their usage for keyword extraction problem has not been fully investigated. In this paper, a keyword extraction technique that uses lexical chains is described, and encouraging results are obtained. \u00a9 2007 Elsevier Ltd. All rights reserved.",
      "publication": "Information Processing and Management",
      "pub_year": 2007,
      "cereb_cite": 16,
      "max_cite": 107,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 1 },
        { "year": 2009, "cite": 1 },
        { "year": 2010, "cite": 3 },
        { "year": 2011, "cite": 3 },
        { "year": 2012, "cite": 1 },
        { "year": 2013, "cite": 2 },
        { "year": 2014, "cite": 2 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 3 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 0 }
      ]
    },
    {
      "title": "Using social media to enhance emergency situation awareness",
      "authors": "['cereb_140149', 'cereb_140150', 'cereb_65285', 'cereb_140151', 'cereb_140152']",
      "abstract": "The described system uses natural language processing and data mining techniques to extract situation awareness information from Twitter messages generated during various disasters and crises. \u00a9 2011 IEEE.",
      "publication": "IEEE Intelligent Systems",
      "pub_year": 2012,
      "cereb_cite": 16,
      "max_cite": 291,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 1 },
        { "year": 2014, "cite": 2 },
        { "year": 2015, "cite": 3 },
        { "year": 2016, "cite": 3 },
        { "year": 2017, "cite": 5 },
        { "year": 2018, "cite": 2 }
      ]
    },
    {
      "title": "Enhancing deep learning sentiment analysis with ensemble techniques in social applications",
      "authors": "['cereb_262265', 'cereb_262266', 'cereb_262267', 'cereb_14642']",
      "abstract": "Deep learning techniques for Sentiment Analysis have become very popular. They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods). Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods. These long-established approaches can yield strong baselines, and their predictive capabilities can be used in conjunction with the arising deep learning methods. In this paper we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches based on manually extracted features. The contributions of this paper are sixfold. First, we develop a deep learning based sentiment classifier using a word embeddings model and a linear machine learning algorithm. This classifier serves as a baseline to compare to subsequent results. Second, we propose two ensemble techniques which aggregate our baseline classifier with other surface classifiers widely used in Sentiment Analysis. Third, we also propose two models for combining both surface and deep features to merge information from several sources. Fourth, we introduce a taxonomy for classifying the different models found in the literature, as well as the ones we propose. Fifth, we conduct several experiments to compare the performance of these models with the deep learning baseline. For this, we use seven public datasets that were extracted from the microblogging and movie reviews domain. Finally, as a result, a statistical study confirms that the performance of these proposed models surpasses that of our original baseline on Fl-Score. (C) 2017 The Authors. Published by Elsevier Ltd.",
      "publication": "Expert Systems with Applications",
      "pub_year": 2017,
      "cereb_cite": 16,
      "max_cite": 15,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 4 },
        { "year": 2018, "cite": 12 }
      ]
    },
    {
      "title": "Training and testing low-degree polynomial data mappings via linear SVM",
      "authors": "['cereb_155642', 'cereb_113700', 'cereb_113699', 'cereb_155643', 'cereb_108468']",
      "abstract": "Kernel techniques have long been used in SVM to handle linearly inseparable problems by transforming data to a high dimensional space, but training and testing large data sets is often time consuming. In contrast, we can efficiently train and test much larger data sets using linear SVM without kernels. In this work, we apply fast linear-SVM methods to the explicit form of polynomially mapped data and investigate implementation issues. The approach enjoys fast training and testing, but may sometimes achieve accuracy close to that of using highly nonlinear kernels. Empirical experiments show that the proposed method is useful for certain large-scale data sets. We successfully apply the proposed method to a natural language processing (NLP) application by improving the testing accuracy under some training/testing speed requirements. \u00a92010 Yin-Wen Chang, Cho-Jui Hsieh, Kai-Wei Chang, Michael Ringgaard and Chih-Jen Lin.",
      "publication": "Journal of Machine Learning Research",
      "pub_year": 2010,
      "cereb_cite": 16,
      "max_cite": 153,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 1 },
        { "year": 2011, "cite": 1 },
        { "year": 2012, "cite": 2 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 3 },
        { "year": 2015, "cite": 3 },
        { "year": 2016, "cite": 2 },
        { "year": 2017, "cite": 1 },
        { "year": 2018, "cite": 3 }
      ]
    }
  ],
  "trending": [
    {
      "title": "Natural Language Processing (almost) from Scratch",
      "authors": "['cereb_116781', 'cereb_116782', 'cereb_116783', 'cereb_116784', 'cereb_116785', 'cereb_79648']",
      "abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements. \u00a9 2011 Ronan Collobert, Jason Weston, L\u00e9on Bottou, Michael Karlen, Koray Kavukcuoglu and Pavel Kuksa.",
      "publication": "Journal of Machine Learning Research",
      "pub_year": 2011,
      "cereb_cite": 268,
      "max_cite": 1744,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 4 },
        { "year": 2014, "cite": 16 },
        { "year": 2015, "cite": 45 },
        { "year": 2016, "cite": 66 },
        { "year": 2017, "cite": 85 },
        { "year": 2018, "cite": 52 }
      ]
    },
    {
      "title": "Deep Learning-Based Document Modeling for Personality Detection from Text",
      "authors": "['cereb_215378', 'cereb_165089', 'cereb_2905', 'cereb_134926']",
      "abstract": "This article presents a deep learning based method for determining the author's personality type from text: given a text, the presence or absence of the Big Five traits is detected in the author's psychological profile. For each of the five traits, the authors train a separate binary classifier, with identical architecture, based on a novel document modeling technique. Namely, the classifier is implemented as a specially designed deep convolutional neural network, with injection of the document-level Mairesse features, extracted directly from the text, into an inner layer. The first layers of the network treat each sentence of the text separately; then the sentences are aggregated into the document vector. Filtering out emotionally neutral input sentences improved the performance. This method outperformed the state of the art for all five traits, and the implementation is freely available for research purposes.",
      "publication": "IEEE Intelligent Systems",
      "pub_year": 2017,
      "cereb_cite": 35,
      "max_cite": 39,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 20 },
        { "year": 2018, "cite": 15 }
      ]
    },
    {
      "title": "A review of natural language processing techniques for opinion mining systems",
      "authors": "['cereb_142823', 'cereb_230949', 'cereb_230950']",
      "abstract": "\u00a9 2016 Elsevier B.V. As the prevalence of social media on the Internet, opinion mining has become an essential approach to analyzing so many data. Various applications appear in a wide range of industrial domains. Meanwhile, opinions have diverse expressions which bring along research challenges. Both of the practical demands and research challenges make opinion mining an active research area in recent years. In this paper, we present a review of Natural Language Processing (NLP) techniques for opinion mining. First, we introduce general NLP techniques which are required for text preprocessing. Second, we investigate the approaches of opinion mining for different levels and situations. Then we introduce comparative opinion mining and deep learning approaches for opinion mining. Opinion summarization and advanced topics are introduced later. Finally, we discuss some challenges and open problems related to opinion mining.",
      "publication": "Information Fusion",
      "pub_year": 2017,
      "cereb_cite": 18,
      "max_cite": 29,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 7 },
        { "year": 2018, "cite": 11 }
      ]
    },
    {
      "title": "Deep learning: yesterday, today, and tomorrow",
      "authors": "['cereb_115723', 'cereb_159706', 'cereb_155351', 'cereb_122149']",
      "abstract": "Machine learning is an important area of artificial intelligence. Since 1980s, huge success has been achieved in terms of algorithms, theory, and applications. From 2006, a new machine learning paradigm, named deep learning, has been popular in the research community, and has become a huge wave of technology trend for big data and artificial intelligence. Deep learning simulates the hierarchical structure of human brain, processing data from lower level to higher level, and gradually composing more and more semantic concepts. In recent years, Google, Microsoft, IBM, and Baidu have invested a lot of resources into the R&D of deep learning, making significant progresses on speech recognition, image understanding, natural language processing, and online advertising. In terms of the contribution to real-world applications, deep learning is perhaps the most successful progress made by the machine learning community in the last 10 years. In this article, we will give a high-level overview about the past and current stage of deep learning, discuss the main challenges, and share our views on the future development of deep learning.",
      "publication": "Jisuanji Yanjiu yu FazhanComputer Research and Development",
      "pub_year": 2013,
      "cereb_cite": 34,
      "max_cite": 73,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 2 },
        { "year": 2015, "cite": 6 },
        { "year": 2016, "cite": 9 },
        { "year": 2017, "cite": 13 },
        { "year": 2018, "cite": 4 }
      ]
    },
    {
      "title": "Enhancing deep learning sentiment analysis with ensemble techniques in social applications",
      "authors": "['cereb_262265', 'cereb_262266', 'cereb_262267', 'cereb_14642']",
      "abstract": "Deep learning techniques for Sentiment Analysis have become very popular. They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods). Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods. These long-established approaches can yield strong baselines, and their predictive capabilities can be used in conjunction with the arising deep learning methods. In this paper we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches based on manually extracted features. The contributions of this paper are sixfold. First, we develop a deep learning based sentiment classifier using a word embeddings model and a linear machine learning algorithm. This classifier serves as a baseline to compare to subsequent results. Second, we propose two ensemble techniques which aggregate our baseline classifier with other surface classifiers widely used in Sentiment Analysis. Third, we also propose two models for combining both surface and deep features to merge information from several sources. Fourth, we introduce a taxonomy for classifying the different models found in the literature, as well as the ones we propose. Fifth, we conduct several experiments to compare the performance of these models with the deep learning baseline. For this, we use seven public datasets that were extracted from the microblogging and movie reviews domain. Finally, as a result, a statistical study confirms that the performance of these proposed models surpasses that of our original baseline on Fl-Score. (C) 2017 The Authors. Published by Elsevier Ltd.",
      "publication": "Expert Systems with Applications",
      "pub_year": 2017,
      "cereb_cite": 16,
      "max_cite": 15,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 4 },
        { "year": 2018, "cite": 12 }
      ]
    },
    {
      "title": "Pharmacovigilance from social media: Mining adverse drug reaction mentions using sequence labeling with word embedding cluster features",
      "authors": "['cereb_163148', 'cereb_163146', 'cereb_163149', 'cereb_163147', 'cereb_35972']",
      "abstract": "\u00a9 The Author 2015.Objective Social media is becoming increasingly popular as a platform for sharing personal health-related information. This information can be utilized for public health monitoring tasks, particularly for pharmacovigilance, via the use of natural language processing (NLP) techniques. However, the language in social media is highly informal, and userexpressed medical concepts are often nontechnical, descriptive, and challenging to extract. There has been limited progress in addressing these challenges, and thus far, advanced machine learning-based NLP techniques have been underutilized. Our objective is to design a machine learning-based approach to extract mentions of adverse drug reactions (ADRs) from highly informal text in social media. Methods: We introduce ADRMine, a machine learning-based concept extraction system that uses conditional random fields (CRFs). ADRMine utilizes a variety of features, including a novel feature for modeling words' semantic similarities. The similarities are modeled by clustering words based on unsupervised, pretrained word representation vectors (embeddings) generated from unlabeled user posts in social media using a deep learning technique. Results: ADRMine outperforms several strong baseline systems in the ADR extraction task by achieving an F-measure of 0.82. Feature analysis demonstrates that the proposed word cluster features significantly improve extraction performance. Conclusion: It is possible to extract complex medical concepts, with relatively high performance, from informal, usergenerated content. Our approach is particularly scalable, suitable for social media mining, as it relies on large volumes of unlabeled data, thus diminishing the need for large, annotated training data sets.",
      "publication": "Journal of the American Medical Informatics Association",
      "pub_year": 2015,
      "cereb_cite": 11,
      "max_cite": 97,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 1 },
        { "year": 2017, "cite": 7 },
        { "year": 2018, "cite": 3 }
      ]
    },
    {
      "title": "Dual Sentiment Analysis: Considering Two Sides of One Review",
      "authors": "['cereb_135874', 'cereb_172177', 'cereb_146354', 'cereb_229678', 'cereb_210006', ['cereb_174266', 'cereb_115894']]",
      "abstract": "\u00a9 2015 IEEE. Bag-of-words (BOW) is now the most popular way to model text in statistical machine learning approaches in sentiment analysis. However, the performance of BOW sometimes remains limited due to some fundamental deficiencies in handling the polarity shift problem. We propose a model called dual sentiment analysis (DSA), to address this problem for sentiment classification. We first propose a novel data expansion technique by creating a sentiment-reversed review for each training and test review. On this basis, we propose a dual training algorithm to make use of original and reversed training reviews in pairs for learning a sentiment classifier, and a dual prediction algorithm to classify the test reviews by considering two sides of one review. We also extend the DSA framework from polarity (positive-negative) classification to 3-class (positive-negative-neutral) classification, by taking the neutral reviews into consideration. Finally, we develop a corpus-based method to construct a pseudo-antonym dictionary, which removes DSA's dependency on an external antonym dictionary for review reversion. We conduct a wide range of experiments including two tasks, nine datasets, two antonym dictionaries, three classification algorithms, and two types of features. The results demonstrate the effectiveness of DSA in supervised sentiment classification.",
      "publication": "IEEE Transactions on Knowledge and Data Engineering",
      "pub_year": 2015,
      "cereb_cite": 10,
      "max_cite": 30,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 3 },
        { "year": 2017, "cite": 5 },
        { "year": 2018, "cite": 2 }
      ]
    },
    {
      "title": "Annotating expressions of opinions and emotions in language",
      "authors": "['cereb_117872', 'cereb_117871', 'cereb_126709']",
      "abstract": "This paper describes a corpus annotation project to study issues in the manual annotation of opinions, emotions, sentiments, speculations, evaluations and other private states in language. The resulting corpus annotation scheme is described, as well as examples of its use. In addition, the manual annotation process and the results of an inter-annotator agreement study on a 10,000-sentence corpus of articles drawn from the world press are presented. \u00a9 Springer 2006.",
      "publication": "Language Resources and Evaluation",
      "pub_year": 2005,
      "cereb_cite": 56,
      "max_cite": 651,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 2 },
        { "year": 2007, "cite": 4 },
        { "year": 2008, "cite": 5 },
        { "year": 2009, "cite": 2 },
        { "year": 2010, "cite": 6 },
        { "year": 2011, "cite": 3 },
        { "year": 2012, "cite": 3 },
        { "year": 2013, "cite": 6 },
        { "year": 2014, "cite": 2 },
        { "year": 2015, "cite": 7 },
        { "year": 2016, "cite": 8 },
        { "year": 2017, "cite": 5 },
        { "year": 2018, "cite": 3 }
      ]
    },
    {
      "title": "Sentiment analysis using product review data",
      "authors": "['cereb_190258', 'cereb_190259']",
      "abstract": "\u00a9 2015, Fang and Zhan; licensee Springer. Sentiment analysis or opinion mining is one of the major tasks of NLP (Natural Language Processing). Sentiment analysis has gain much attention in recent years. In this paper, we aim to tackle the problem of sentiment polarity categorization, which is one of the fundamental problems of sentiment analysis. A general process for sentiment polarity categorization is proposed with detailed process descriptions. Data used in this study are online product reviews collected from Amazon.com. Experiments for both sentence-level categorization and review-level categorization are performed with promising outcomes. At last, we also give insight into our future work on sentiment analysis.",
      "publication": "Journal of Big Data",
      "pub_year": 2015,
      "cereb_cite": 9,
      "max_cite": 66,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 1 },
        { "year": 2017, "cite": 5 },
        { "year": 2018, "cite": 3 }
      ]
    },
    {
      "title": "Extraction of emotions from multilingual text using intelligent text processing and computational linguistics",
      "authors": "['cereb_103403', 'cereb_287163', 'cereb_96266']",
      "abstract": "\u00a9 2017 Elsevier B.V.Extraction of Emotions from Multilingual Text posted on social media by different categories of users is one of the crucial tasks in the field of opining mining and sentiment analysis. Every major event in the world has an online presence and social media. Users use social media platforms to express their sentiments and opinions towards it. In this paper, an advanced framework for detection of emotions of users in Multilanguage text data using emotion theories has been presented, which deals with linguistics and psychology. The emotion extraction system is developed based on multiple features groups for the better understanding of emotion lexicons. Empirical studies of three real-time events in domains like a Political election, healthcare, and sports are performed using proposed framework. The technique used for dynamic keywords collection is based on RSS (Rich Site Summary) feeds of headlines of news articles and trending hashtags from Twitter. An intelligent data collection model has been developed using dynamic keywords. Every word of emotion contained in a tweet is important in decision making and hence to retain the importance of multilingual emotional words, effective pre-processing technique has been used. Naive Bayes algorithm and Support Vector Machine (SVM) are used for fine-grained emotions classification of tweets. Experiments conducted on collected data sets, show that the proposed method performs better in comparison to corpus-driven approach which assign affective orientation or scores to words. The proposed emotion extraction framework performs better on the collected dataset by combining feature sets consisting of words from publicly available lexical resources. Furthermore, the presented work for extraction of emotion from tweets performs better in comparisons of other popular sentiment analysis techniques which are dependent of specific existing affect lexicons.",
      "publication": "Journal of Computational Science",
      "pub_year": 2017,
      "cereb_cite": 7,
      "max_cite": 8,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 1 },
        { "year": 2018, "cite": 6 }
      ]
    }
  ],
  "new": [
    {
      "title": "Towards automatic filtering of fake reviews",
      "authors": "['cereb_28989', 'cereb_84641', 'cereb_100130']",
      "abstract": "\u00a9 2018 Elsevier B.V. Online opinions significantly influence consumer purchase decisions. Unfortunately, this has led to a dramatic increase of fake (or spam) reviews that can damage the reputation of brands and artificially manipulate users\u2019 perceptions about products and companies. Despite the efforts of several studies on fake review detection, important questions still remain open. For instance, there is no consensus if the performance of the classification methods is affected when they are used in real-world scenarios that require online learning. Moreover, it is also not known if the performance of the methods decreases due to the time-ordered nature of the reviews. To answer these and other important open questions, this work presents a comprehensive analysis of content-based classification methods for fake review detection. The experiments were performed in multiple settings, employing different types of learning and datasets. A careful analysis of the results provided sufficient evidence to respond appropriately to the open questions, which can be used as a baseline for future studies.",
      "publication": "Neurocomputing",
      "pub_year": 2018,
      "cereb_cite": 2,
      "max_cite": 0,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 2 }
      ]
    },
    {
      "title": "Bag of meta-words: A novel method to represent document for the sentiment classification",
      "authors": "['cereb_326926', 'cereb_179053', 'cereb_184496', 'cereb_224405']",
      "abstract": "\u00a9 2018 Elsevier Ltd It is crucial to represent the semantic information of a document in sentiment classification. Various semantic information representation models have been proposed, however existing approaches have their setbacks. Notable weaknesses among these are: (1) tradition VSM methods, completely ignore the semantic information; (2) averaging word embedding methods, cannot depict the synthetical semantic meaning of the given document; (3) neural network methods, require complex structure and are notoriously difficult to be trained. To overcome these limitations, we introduce a simple but novel method which we call bag of meta-words (BoMW). In our method, the semantic information of the document is indicated by a meta-words vector in which every single meta-word element denotes particular semantic information. Especially, these meta-words are extracted from pre-trained word embeddings through two different but complemental models, naive interval meta-words (NIM) and feature combination meta-words (FCM). In general, our new model BoMW is as simple as traditional VSM model but it can capture the synthetical semantic meanings of the document. Numerous experiments on two benchmarks (IMDB dataset and Pang's dataset) are carried out to verify the effectiveness of the proposed method, and the results show that the performance of our method can exceed the traditional VSM methods and methods using pre-trained word embedding.",
      "publication": "Expert Systems with Applications",
      "pub_year": 2018,
      "cereb_cite": 2,
      "max_cite": 0,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 2 }
      ]
    },
    {
      "title": "Quantitative Analysis of Uncertainty in Medical Reporting: Creating a Standardized and Objective Methodology",
      "authors": "['cereb_13532']",
      "abstract": "\u00a9 2017, Society for Imaging Informatics in Medicine.Uncertainty in text-based medical reports has long been recognized as problematic, frequently resulting in misunderstanding and miscommunication. One strategy for addressing the negative clinical ramifications of report uncertainty would be the creation of a standardized methodology for characterizing and quantifying uncertainty language, which could provide both the report author and reader with context related to the perceived level of diagnostic confidence and accuracy. A number of computerized strategies could be employed in the creation of this analysis including string search, natural language processing and understanding, histogram analysis, topic modeling, and machine learning. The derived uncertainty data offers the potential to objectively analyze report uncertainty in real time and correlate with outcomes analysis for the purpose of context and user-specific decision support at the point of care, where intervention would have the greatest clinical impact.",
      "publication": "Journal of Digital Imaging",
      "pub_year": 2018,
      "cereb_cite": 1,
      "max_cite": 0,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 1 }
      ]
    },
    {
      "title": "Deep learning based spell checker for Malayalam language",
      "authors": "['cereb_407986', 'cereb_320052', 'cereb_5179', 'cereb_57041']",
      "abstract": "Spell checking plays an important role in conveying correct information and hence helps in clear communication. Spell checkers for English language are well established. But in case of Indian languages, especially Malayalam lacks a well developed spell checker. The spell checkers that currently exist for Indian languages are based on traditional approaches such as rule based or dictionary based. The rich morphological nature of Malayalam makes spell checking a difficult task. The proposed work is a novel attempt and first of its kind that focuses on implementing a spell checker for Malayalam using deep learning. The spell checker comprises of two processes: error detection and error correction. The error detection section employs a LSTM based neural network which is trained to identify the misspelled words and the position where the error has occurred. The error detection accuracy is measured using the F1 score. Error correction is achieved by the selecting the most probable word from the candidate word suggestions.",
      "publication": "Journal of Intelligent and Fuzzy Systems",
      "pub_year": 2018,
      "cereb_cite": 1,
      "max_cite": 1,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 1 }
      ]
    },
    {
      "title": "Polish texts topic classification evaluation",
      "authors": "['cereb_318760', 'cereb_327368']",
      "abstract": "Copyright \u00a9 2018 by SCITEPRESS \u2013 Science and Technology Publications, Lda. All rights reserved. The paper presents preparation, lead and results of evaluation of efficiency of text classification (TC) methods for Polish. The subject language is of complex morphology, it belongs to flexional languages. Thus there is a strong need of making proper text preprocessing in order to guarantee reliable TC. Basing on authors\u2019 practical experience from former TC, IR and general NLP experiments set of preprocessing rules was applied. Also feature-documents matrix was designed with respect to the most promising feature selected. About 216 experiments on exemplar corpus in subject (topic) classification task, with different preprocessing, weighting, filtering (for dimensions reduction) schemes and classifiers was conducted. Results shows there is not substantial increase of accuracy when using most of classical pre-processing steps in case of corpus of large size (at least 1000 exemplars per class). The highest impact authors were able to obtain concerned the system costs of TC processes, not the TC accuracy.",
      "publication": "ICAART   Proceedings of the  International Conference on Agents and Artificial Intelligence",
      "pub_year": 2018,
      "cereb_cite": 1,
      "max_cite": 2,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 1 }
      ]
    },
    {
      "title": "Automatic Extraction of Access Control Policies from Natural Language Documents",
      "authors": "['cereb_301750', 'cereb_209311', 'cereb_87300']",
      "abstract": "IEEE A fundamental management responsibility is securing information systems. Almost all applications that deal with safety, privacy, or defense include some form of access control. There are a plethora of access control models in the information security realm such as role-based access control and attribute-based access control. However, the initial development of access control policies (ACPs) can be very challenging. Most organizations have high-level requirement specifications that include a set of ACPs, which describe allowable operations of the system. It is time consuming and error-prone to manually sift through these documents and extract ACPs. In this paper, we propose a new framework towards extracting ACPs from unrestricted natural language documents using semantic role labeling (SRL). We were able to correctly identify ACP elements with an average <formula><tex>$F_1$</tex></formula> score of 75%, which bested the previous work by 15%. Furthermore, as SRL tools are often trained on publicly available corpora such as Wall Street Journal, we investigated the idea of improving SRL performance using domain-related knowledge. We utilized domain adaptation and semi-supervised learning techniques and were able to improve the SRL performance by 2% using only a small amount of access control data.",
      "publication": "IEEE Transactions on Dependable and Secure Computing",
      "pub_year": 2018,
      "cereb_cite": 1,
      "max_cite": 1,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 1 }
      ]
    },
    {
      "title": "Caching for Mobile Social Networks with Deep Learning: Twitter Analysis for 2016 U.S. Election",
      "authors": "['cereb_57547', 'cereb_60056', 'cereb_130039']",
      "abstract": "As the rise of the portable devices, people usually access the social media such as Twitter and Facebook through wireless networks. Therefore, data transmission rates significant important to the end users. In this work, we discuss the problem of context-aware data caching in the heterogeneous small cell networks to reduce the service delay and how the device-to-device (D2D) and device-to-infrastructure (D2I) improve the system social welfare. In the data-caching model, we explore three types of cache entities, macro cell base stations, small cell base stations, and end user devices. We propose a long short-term memory (LSTM) deep learning model to perform data analysis and extract information content from the data. By knowing the interest of the data to the cache entities, we can cache the data that will most likely to be requested by the end users to reduce service latency. In simulation, we show our proposed algorithm can efficiently reduce the service latency during 2016 U.S. presidential election where mobile user were urgent to request the election information through wireless networks. Comparing with other mechanisms such as using one-to-many matching algorithm or without D2D communication technology, our proposed algorithm improves significantly on the devices performance and system social welfare.",
      "publication": "IEEE Transactions on Network Science and Engineering",
      "pub_year": 2018,
      "cereb_cite": 0,
      "max_cite": 0,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 0 }
      ]
    },
    {
      "title": "LAWBO: A smart lawyer chatbot",
      "authors": "['cereb_368352', 'cereb_368353', 'cereb_368354']",
      "abstract": "\u00a9 2018 ACM. When it comes to conversing and understanding like humans, one of the most intricate domains for chatbots is the judicial system. One needs to really pour into volumes of legal books and judgment papers to analyze and investigate a case. \u201cJustice delayed is justice denied!\u201d. With time being a big constraint, LAWBO could draw parallelism between cases and guide the lawyers by giving relevant information for the given queries. We use a combination of heuristics applied on data extracted from Supreme Court judgments using in-house developed, state-of-the-art parsers, dynamic memory networks (DMN) and GloVe word representation for Natural Language Processing (NLP).",
      "publication": "ACM International Conference Proceeding Series",
      "pub_year": 2018,
      "cereb_cite": 0,
      "max_cite": 0,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 0 }
      ]
    },
    {
      "title": "Scarlet - Artificial Teaching Assistant",
      "authors": "['cereb_368318', 'cereb_368319', 'cereb_368320', 'cereb_368321']",
      "abstract": "\u00a9 2017 IEEE. Scarlet an Artificial Teaching Assistant is a personal digital assistant that has been developed with main aim to assist students in their learning process by ensuring fast and efficiently search of documents and learning materials. Scarlet is able to give an adequate response to a specific question based on knowledge gathered by an unique algorithm which enables her to recognize context during file and web page content search. After finding the most appropriate answer Scarlet seeks for student feedback in order to improve future search. The metric proposed is based on the power law which occurs in natural language, that is the Zipfian distribution[1]. It is designed to work for any spoken language although it might work on some better than other depending on the nature of the language, the structure, grammar and semantics. The method uses this metric to derive context from data and then queries the data source looking for the best match. The whole implementation is rounded off by a learning module which gives the system a learning curve based on users (students) scoring how relevant the output is among other parameters.",
      "publication": "Proceedings   International Conference on Control Artificial Intelligence Robotics and Optimization ICCAIRO",
      "pub_year": 2018,
      "cereb_cite": 0,
      "max_cite": 0,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 0 }
      ]
    },
    {
      "title": "Twitter sentiment analysis of DKI Jakarta's gubernatorial election 2017 with predictive and descriptive approaches",
      "authors": "['cereb_24406', 'cereb_8130', 'cereb_368441']",
      "abstract": "\u00a9 2017 IEEE. The main purpose of this research is to analyze sentiment of DKI Jakarta's gubernatorial election 2017 in social media Twitter with predictive and descriptive approaches. The dataset were collected from Twitter by using each candidate's username as the search query. For the predictive approach, machine learning algorithms such as Multinomial Naive Bayes and Support Vector Machine are used to classify the dataset. As for the descriptive approach, time series graphs and wordclouds are used to get the deeper insights of the dataset and find the connection between Twitter's sentiment and the result of the election itself.",
      "publication": "Proceedings   International Conference on Computer Control Informatics and its Applications Emerging Trends In Computational Science and Engineering ICINA",
      "pub_year": 2018,
      "cereb_cite": 0,
      "max_cite": 0,
      "citeburst": [
        { "year": 1969, "cite": 0 },
        { "year": 1970, "cite": 0 },
        { "year": 1971, "cite": 0 },
        { "year": 1972, "cite": 0 },
        { "year": 1973, "cite": 0 },
        { "year": 1974, "cite": 0 },
        { "year": 1975, "cite": 0 },
        { "year": 1976, "cite": 0 },
        { "year": 1977, "cite": 0 },
        { "year": 1978, "cite": 0 },
        { "year": 1979, "cite": 0 },
        { "year": 1980, "cite": 0 },
        { "year": 1981, "cite": 0 },
        { "year": 1982, "cite": 0 },
        { "year": 1983, "cite": 0 },
        { "year": 1984, "cite": 0 },
        { "year": 1985, "cite": 0 },
        { "year": 1986, "cite": 0 },
        { "year": 1987, "cite": 0 },
        { "year": 1988, "cite": 0 },
        { "year": 1989, "cite": 0 },
        { "year": 1990, "cite": 0 },
        { "year": 1991, "cite": 0 },
        { "year": 1992, "cite": 0 },
        { "year": 1993, "cite": 0 },
        { "year": 1994, "cite": 0 },
        { "year": 1995, "cite": 0 },
        { "year": 1996, "cite": 0 },
        { "year": 1997, "cite": 0 },
        { "year": 1998, "cite": 0 },
        { "year": 1999, "cite": 0 },
        { "year": 2000, "cite": 0 },
        { "year": 2001, "cite": 0 },
        { "year": 2002, "cite": 0 },
        { "year": 2003, "cite": 0 },
        { "year": 2004, "cite": 0 },
        { "year": 2005, "cite": 0 },
        { "year": 2006, "cite": 0 },
        { "year": 2007, "cite": 0 },
        { "year": 2008, "cite": 0 },
        { "year": 2009, "cite": 0 },
        { "year": 2010, "cite": 0 },
        { "year": 2011, "cite": 0 },
        { "year": 2012, "cite": 0 },
        { "year": 2013, "cite": 0 },
        { "year": 2014, "cite": 0 },
        { "year": 2015, "cite": 0 },
        { "year": 2016, "cite": 0 },
        { "year": 2017, "cite": 0 },
        { "year": 2018, "cite": 0 }
      ]
    }
  ]
}
